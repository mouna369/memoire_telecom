# #!/usr/bin/env python3
# from pymongo import MongoClient
# from datetime import datetime

# print("="*60)
# print("ğŸ” VÃ‰RIFICATION COMPLÃˆTE DE MONGODB")
# print("="*60)

# # Connexion
# client = MongoClient('localhost', 27017)
# db = client['telecom_algerie']
# collection = db['commentaires_bruts']

# # 1. Total gÃ©nÃ©ral
# total = collection.count_documents({})
# print(f"\nğŸ“Š TOTAL: {total} commentaires")

# # 2. RÃ©partition par fichier
# print("\nğŸ“ RÃ‰PARTITION PAR FICHIER SOURCE:")
# pipeline_fichiers = [
#     {"$group": {"_id": "$metadata.fichier", "count": {"$sum": 1}}}
# ]
# for doc in collection.aggregate(pipeline_fichiers):
#     print(f"   {doc['_id']}: {doc['count']}")

# # 3. RÃ©partition par source (rÃ©seau social)
# print("\nğŸ“± RÃ‰PARTITION PAR SOURCE:")
# pipeline_source = [
#     {"$group": {"_id": "$source", "count": {"$sum": 1}}},
#     {"$sort": {"count": -1}}
# ]
# for doc in collection.aggregate(pipeline_source):
#     print(f"   {doc['_id']}: {doc['count']}")

# # 4. Afficher 3 exemples
# print("\nğŸ“ 3 PREMIERS COMMENTAIRES:")
# for doc in collection.find().limit(3):
#     print(f"\n   ğŸ“„ Fichier: {doc['metadata']['fichier']}")
#     print(f"   ğŸ’¬ Texte: {doc['texte_original'][:100]}...")
#     print(f"   ğŸ“… Date: {doc['date']}")
#     print(f"   ğŸ“± Source: {doc['source']}")

# # 5. Statistiques rapides
# print("\nğŸ“Š STATISTIQUES:")
# print(f"   ğŸ”¹ Commentaires avec date: {collection.count_documents({'date': {'$ne': ''}})}")
# print(f"   ğŸ”¹ Commentaires sans date: {collection.count_documents({'date': ''})}")
# print(f"   ğŸ”¹ Commentaires Facebook: {collection.count_documents({'source': 'Facebook'})}")
# print(f"   ğŸ”¹ Commentaires Twitter: {collection.count_documents({'source': 'Twitter'})}")

# print("\n" + "="*60)
# print("âœ… VÃ‰RIFICATION TERMINÃ‰E")
# print("="*60)
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import pandas as pd
import glob
import os
import subprocess

print("="*60)
print("ğŸ“Š ANALYSE DES RÃ‰SULTATS DU NETTOYAGE")
print("="*60)

# Chemin vers les rÃ©sultats
base_path = "/home/mouna/projet_telecom/data/results/commentaires_sans_urls.parquet"

# 1. VÃ©rifier que le dossier existe
if not os.path.exists(base_path):
    print(f"âŒ Dossier non trouvÃ©: {base_path}")
    print("ğŸ“ VÃ©rifiez le chemin:")
    os.system("ls -la /home/mouna/projet_telecom/data/results/")
    exit(1)

print(f"ğŸ“ Dossier trouvÃ©: {base_path}")

# 2. Voir TOUT le contenu avec sudo
print("\nğŸ” Contenu COMPLET du dossier (avec sudo):")
subprocess.run(f"sudo ls -la {base_path}/", shell=True)

# 3. Chercher tous les dossiers task_
print("\nğŸ” Recherche des dossiers task_...")
task_dirs = subprocess.getoutput(f"sudo find {base_path} -type d -name 'task_*'").split('\n')
task_dirs = [d for d in task_dirs if d]  # Enlever les lignes vides

print(f"âœ… {len(task_dirs)} dossiers task_ trouvÃ©s")

# 4. Chercher les fichiers Parquet dans ces dossiers
print("\nğŸ“‚ Recherche des fichiers Parquet...")
all_files = []

for task_dir in task_dirs:
    files = subprocess.getoutput(f"sudo find {task_dir} -name '*.parquet'").split('\n')
    for f in files:
        if f and not f.endswith('.crc'):  # Ignorer les fichiers .crc
            all_files.append(f)
            print(f"   âœ“ {os.path.basename(task_dir)}/{os.path.basename(f)}")

print(f"\nâœ… {len(all_files)} fichiers Parquet trouvÃ©s")

# 5. Copier les fichiers dans un dossier temporaire avec les bonnes permissions
if all_files:
    temp_dir = "/tmp/resultats_parquet"
    os.makedirs(temp_dir, exist_ok=True)
    os.system(f"sudo chmod 777 {temp_dir}")
    
    print(f"\nğŸ“‹ Copie des fichiers vers {temp_dir}...")
    for i, file in enumerate(all_files):
        dest = f"{temp_dir}/part-{i:05d}.parquet"
        os.system(f"sudo cp {file} {dest}")
        os.system(f"sudo chmod 644 {dest}")
        print(f"   {i+1}/{len(all_files)} copiÃ©")
    
    # 6. Lire les fichiers avec pandas
    print("\nğŸ“– Lecture des fichiers...")
    all_dfs = []
    
    for i in range(len(all_files)):
        try:
            df = pd.read_parquet(f"{temp_dir}/part-{i:05d}.parquet")
            all_dfs.append(df)
            print(f"   âœ“ Partie {i+1}: {len(df)} lignes")
        except Exception as e:
            print(f"   âŒ Erreur partie {i+1}: {e}")
    
    # 7. ConcatÃ©ner
    if all_dfs:
        print("\nğŸ”— Fusion des donnÃ©es...")
        df_final = pd.concat(all_dfs, ignore_index=True)
        
        print(f"\nâœ… TOTAL: {len(df_final)} lignes")
        
        # 8. AperÃ§u
        print("\nğŸ‘€ AperÃ§u des 5 premiÃ¨res lignes:")
        if 'Commentaire_Client' in df_final.columns and 'commentaire_clean' in df_final.columns:
            print(df_final[['Commentaire_Client', 'commentaire_clean']].head())
        else:
            print(df_final.head())
        
        # 9. Sauvegarder
        output_file = "/home/mouna/projet_telecom/data/results/commentaires_sans_urlsl.csv"
        df_final.to_csv(output_file, index=False, encoding='utf-8-sig')
        os.system(f"sudo chown mouna:mouna {output_file}")
        print(f"\nğŸ’¾ Fichier CSV sauvegardÃ©: {output_file}")
        
        # 10. Nettoyage
        os.system(f"rm -rf {temp_dir}")
        
    else:
        print("âŒ Aucune donnÃ©e lue!")
else:
    print("âŒ Aucun fichier Parquet trouvÃ©!")

print("\n" + "="*60)
print("ğŸ‰ ANALYSE TERMINÃ‰E")
print("="*60)